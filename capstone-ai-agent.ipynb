{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425d69b8",
   "metadata": {},
   "source": [
    "# Capstone Project: Gen AI Architecture\n",
    "\n",
    "## Server-Side Packages\n",
    "\n",
    "### Core Frameworks\n",
    "```\n",
    "fastapi==0.108.0          # Web API framework\n",
    "uvicorn==0.23.2           # ASGI server\n",
    "langchain==0.1.10         # LLM application framework\n",
    "langchain_core==0.1.28    # LangChain core components\n",
    "langchain_community==0.0.25  # Community components\n",
    "langchain_openai==0.0.5   # OpenAI integration\n",
    "```\n",
    "\n",
    "### Data Storage & Vector Database\n",
    "```\n",
    "redis                     # Caching and vector storage\n",
    "qdrant_client==1.7.1      # Vector database client\n",
    "```\n",
    "\n",
    "### API Integration & Tools\n",
    "```\n",
    "httpx                     # Asynchronous HTTP client\n",
    "websockets                # WebSocket support\n",
    "pydantic>=2.0.0           # Data validation\n",
    "python-dotenv             # Environment variable management\n",
    "```\n",
    "\n",
    "### Ollama Integration\n",
    "```\n",
    "langchain_ollama          # Ollama model integration\n",
    "```\n",
    "\n",
    "### Google API Integration\n",
    "```\n",
    "google-api-python-client  # Google API client\n",
    "google-auth               # Google authentication\n",
    "google-auth-oauthlib      # OAuth authentication\n",
    "google-auth-httplib2      # HTTP auth client\n",
    "```\n",
    "\n",
    "## Client-Side Packages\n",
    "\n",
    "### Discord Bot\n",
    "```\n",
    "discord.py                # Discord bot API\n",
    "```\n",
    "\n",
    "### Chatbot Interface\n",
    "```\n",
    "streamlit                 # Simple web interface builder\n",
    "gradio                    # AI application interface builder\n",
    "```\n",
    "\n",
    "## Ollama Models with Google API Integration\n",
    "\n",
    "Ollama runs models locally, so integrating with Google APIs requires some middleware. Here are implementation approaches:\n",
    "\n",
    "### Approach 1: Using LangChain to Integrate Google API with Ollama\n",
    "```python\n",
    "from langchain_ollama import Ollama\n",
    "from langchain.agents import tool\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Set up Google API\n",
    "google_api_key = \"YOUR_API_KEY\"\n",
    "google_cse_id = \"YOUR_CSE_ID\"  # Custom Search Engine ID\n",
    "\n",
    "# Create Google search tool\n",
    "@tool\n",
    "def google_search(query: str) -> str:\n",
    "    \"\"\"Search Google for relevant information\"\"\"\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=google_api_key)\n",
    "    result = service.cse().list(q=query, cx=google_cse_id).execute()\n",
    "    return str(result['items'])\n",
    "\n",
    "# Initialize Ollama model\n",
    "ollama_model = Ollama(model=\"llama3\")\n",
    "\n",
    "# Integrate with LangChain Agent\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an assistant that can use tools\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "agent = create_react_agent(ollama_model, [google_search], prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[google_search])\n",
    "```\n",
    "\n",
    "### Approach 2: Recommended Ollama Models\n",
    "\n",
    "The following Ollama models work well with Google API integration:\n",
    "\n",
    "1. **llama3** - Meta's latest model with strong general comprehension\n",
    "2. **mistral** - Good for various tasks, especially understanding and generation\n",
    "3. **phi3** - Microsoft's lightweight model for resource-constrained environments\n",
    "4. **gemma** - Google's open-source model with good compatibility with Google APIs\n",
    "\n",
    "## Implementation Suggestions\n",
    "\n",
    "1. First, build the basic FastAPI server framework\n",
    "2. Integrate Ollama models\n",
    "3. Add Google API functionality (search, translation, etc.)\n",
    "4. Implement vector storage and retrieval\n",
    "5. Add agent capabilities\n",
    "6. Finally, develop the client-side interfaces\n",
    "\n",
    "\n",
    "Server-Side Architecture\n",
    "```\n",
    "Client Requests (HTTP/WebSocket) → FastAPI → LangChain → Ollama\n",
    "                                     ↑\n",
    "                                     ↓\n",
    "                              Vector Database/Redis\n",
    "```\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
